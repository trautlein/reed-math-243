%Header
    \documentclass[10pt]{article}
    \usepackage{indentfirst}
    \usepackage{fullpage}
    \usepackage{microtype}
    \usepackage{enumerate}
    \usepackage{amsmath}

    \begin{document}    
    
\noindent{\large
    Hans Trautlein\footnote{I went to Andrew's office hours for help completing this problem set.}          \hfill Problem Set 1\ \ \\
    Due: January 29, 2016   \hfill Andrew Bray}
\bigskip

\section*{Book Problems}

\begin{enumerate}
  \item Indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify my answer.\footnote{Every answer in this Problem Set has referred frequently to Chapter 2 in James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. \emph{An Introduction to Statistical Learning}. New York: Springer, 2013. I have also gotten help from }
  \begin{enumerate}
    \item A flexible method would be appropriate, as you will get a better ``fit'' on the data with a more flexible approach and you have a large enough $n$ to avoid the issues of using a flexible model with a small $n$.
    \item You would want an inflexible method in this circumstance. If you have a small amount of variables you are more likely to have a model that is difficult to fit exactly, and the large amount of predictors might allow you to accidentally the model.
    \item 
    \item If the variance of the error terms, $\sigma^2 = Var(\epsilon)$, is extremely high I would expect a flexible model to be worse than an inflexible method because you might be more likely to overfit your model. In Nate Silver parlance your model would end up confusing the ``signal'' for the ``noise.''
  \end{enumerate}

  \item 
    \begin{enumerate}
      \item $n = 500$, $p = 3$. This a regression problem that is most interested in inference.
      \item $n = 20$, $p = 13$. This is a classification problem that is most interested in prediction.
      \item $n = 52$ (because of weekly data), $p = 3$. This is a regression problem that is most interested in prediction.
    \end{enumerate}
  
  \setcounter{enumi}{3}
  \item
    \begin{enumerate}
      \item Real-life applications of \emph{classification}. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain.
        \begin{enumerate}
          \item
          \item
          \item
        \end{enumerate}
        
      \item Real-life applications of \emph{regression}. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain.
       \begin{enumerate}
          \item
          \item
          \item
        \end{enumerate}
        
      \item Real-life applications of \emph{cluster analysis}.
       \begin{enumerate}
          \item
          \item
          \item
        \end{enumerate}
        
    \end{enumerate}
  
  \item A very inflexible model for regression and classification has both advantages and disadvantages as well, as it often is easier to make inferences from more inflexible methods compared to flexible methods. For example, if inference is the overall goal then you might prefer a less flexible model, like ``least squares'' or ``subset selection lasso'' as opposed to ``support vector machines.'' The restriction inherent in more inflexible models makes inference easier.
 
        A more flexible model allows you to reduce ``bias'' and also fit models that are more complicated that might only be explainable by a simpler and more inflexible model. A more flexible approach might be preferred when prediction is weighed much heavier than inference in the model's goals. This is a slight oversimplification, but then the ``why'' takes a backseat to the ``what,'' that is, the output that the model creator cares about is less a great understanding of the inner workings of the model and why it works that way but instead that the model has the best output possible. This might not be the best approach in the long run though - to at least a tiny degreee you want to understand your models! But adding every variable that you have into the model might result in overfitting. This is further explained on page 26 of the text for this course in section 2.1.3, \emph{The Trade-Off Between Prediction Accuracy and Model Interpretability}.
  
        Overall, flexibility is preferred when you are looking for great prediction and inflexibility is prized when you are looking for easy inference.
  
  \item The differences between a parametric and a non-parametric statistical learning approach are 
  
        The advantages of a parametric approach as opposed to a non-parametric approach are that you already have an assumed ``form'' for the model (linear) so you only have to estimate the coefficients on the variables that you choose to use, instead of having to also figure out whether or not they are going to have some exponent added to them.
        
        Disadvantages parametric approachs are also present though. Parametric approaches might oversimplify the form of the proper function for the best achievable model as the form might be different than the linear form assumed.
  
  \item
    \begin{enumerate}
      \item I have placed my answers in the table below:
        
        \begin{table}[h]
            \centering
            \begin{tabular}{l|llll|c} \hline
                Obs. & $X_1$ & $X_2$ & $X_3$ & $Y$   & Distance       \\ \hline
                1    & 0     & 3     & 0     & Red   & 3              \\
                2    & 2     & 0     & 0     & Red   & 2              \\
                3    & 0     & 1     & 3     & Red   & $\sqrt{10}$    \\
                4    & 0     & 1     & 2     & Green & $\sqrt{5} $    \\
                5    & -1    & 0     & 1     & Green & $\sqrt{2} $    \\
                6    & 1     & 1     & 1     & Red   & $\sqrt{3} $    \\ \hline
            \end{tabular}
        \end{table}

      \item My prediction when $K = 1$ is 
      \item My prediction when $K = 3$ is 
      \item
    \end{enumerate}

\end{enumerate}



\section*{Additional exercise}


Using the notation standards described at the end of chapter one, please provide notation for the following objects:

Input: The 10 photos that we looked at on the first day, as if they were scanned at 64 x 64 pixel resolution.

Transformed Input: The 10 photos, after a small number of features have been identified.

Output: The associated actual ages of those 10 photos.

Model: Provide a guess at what f might look like (there is no single right answer here).

\subsection*{Input}

$$ \mathbf{X} = 
  \begin{pmatrix}
    x_{1,1}  & x_{1,2}  & \cdots & x_{1, 64^2} \\
    x_{2,1}  & x_{2,2}  & \cdots & x_{2, 64^2} \\
    \vdots   & \vdots   & \ddots & \vdots  \\
    x_{10,1} & x_{10,2} & \cdots & x_{10, 64^2} 
\end{pmatrix} $$

\subsection*{Transformed Input}

$$ \mathbf{X} = 
  \begin{pmatrix}
    x_{1,1} & \cdots & x_{1, 15} \\
    \vdots  & \ddots & \vdots  \\
    x_{10,1} & \cdots & x_{10, 15} 
\end{pmatrix} $$

Here it is suggested that there are fifteen different factors that we will pulled out of our input and will end up using in our model. For example, the first factor could be a dummy variable of whether or not the hair is more than 50\% grey, the second factor could be nose length (cm), the third factor could be whether or not crows feet are visible, the fourth factor could be whether or not the person is bald, etc...this would correspond to the columns up above, with each factor having it's own column, and each factor respresented once for each observation.

\subsection*{Output}

$$ \mathbf{y} = 
    \begin{pmatrix}
        y_1 \\
        y_2 \\
        \vdots \\
        y_{10}
    \end{pmatrix} $$

Here each $y$ will be an age, for example, if $y_3 = 43$ that would mean that the modeled age of the person in observation 3 would be forty-three years old.

\subsection*{Model}

Here is where I'll put my model



\end{document}

